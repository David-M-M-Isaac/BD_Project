{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb50b77f-ab6c-4a76-8970-087b006dae0b",
   "metadata": {},
   "source": [
    "# üìú Tratamento dos dados entre videos do Youtube e os stocks de grandes empresas üìú "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0a682-7e23-49c5-b062-78bf2c0ea988",
   "metadata": {},
   "source": [
    "## Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73834437-850c-4a9d-8213-5bb85526c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from datetime import datetime\n",
    "import re\n",
    "from functools import reduce\n",
    "from matplotlib import cbook, cm\n",
    "from matplotlib.colors import LightSource\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70724a25-31ce-49b2-9142-0688ffef9bd5",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do Spark para ser utilizado em PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c863b017-fa74-4c6e-ac94-0f5e8e2e60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_ = SparkSession.builder \\\n",
    "    .appName(\"company_database\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongodb:27017/Company_Database\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongodb:27017/Company_Database\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongodb:27017/Youtube_Database\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongodb:27017/Youtube_Database\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"7g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cf114-4c96-4d40-ac49-355fa38de3ff",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Para a realiza√ß√£o deste trabalho, foram utilizados 14 datasets que se dividem em dois grupos principais: os datasets de v√≠deos do YouTube e datasets de stocks de empresas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f8fc4-3a7f-481f-91fd-3e360a75f092",
   "metadata": {},
   "source": [
    "## Importan√ß√£o dos dados de cada pais\n",
    "Datasets de v√≠deos do youtube <br>\n",
    "Os dados destes datasets s√£o provenientes de oito diferentes pa√≠ses, dos quais: Brasil, Estados Unidos (US), Canad√°, Fran√ßa, Inglaterra, √çndia, Coreia do Sul e M√©xico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c35168-23c6-417c-8eef-e79a4404dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_us\").load()\n",
    "df_br = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_br\").load()\n",
    "df_ca = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_ca\").load()\n",
    "df_fr = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_fr\").load()\n",
    "df_gb = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_gb\").load()\n",
    "df_in = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_in\").load()\n",
    "df_kr = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_kr\").load()\n",
    "df_mx = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_mx\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c28df-34bf-4db7-9e96-c51ba55e3c2c",
   "metadata": {},
   "source": [
    "## Importan√ß√£o dos dados de empresa\n",
    "Datasets de stocks de empresas <br>\n",
    "Os datasets sobre os stocks de empresas fornecem dados de seis organiza√ß√µes distintas: Sony, Nvidia, Microsoft, Dell, IBM, Intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e930414f-e83c-41b7-bcf2-f9ebb14ae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dell = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.dell_data\").load()\n",
    "df_ibm = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.ibm_data\").load()\n",
    "df_intel = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.intel_data\").load()\n",
    "df_microsoft = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.microsoft_data\").load()\n",
    "df_nvidia = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.nvidia_data\").load()\n",
    "df_sony = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.sony_data\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71688b-f487-49ec-9dc6-00aa0e1d20d7",
   "metadata": {},
   "source": [
    "## Dicionario das empresas e seus nomes para posteriormente fazer a uni√£o dos dfs com a coluna company_name\n",
    "A ideia √© juntar todos os dataframes num s√≥. Para isso, necessitamos de criar uma nova coluna que identifique a que empresa a linha do stock est√° ligada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aa3911b-e194-4b90-a298-ee060f735779",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_companies = {'companies': [\n",
    "                 {'dataframe':df_dell, 'name': 'dell'},\n",
    "                 {'dataframe':df_ibm, 'name': 'ibm'},\n",
    "                 {'dataframe':df_intel, 'name': 'intel'},\n",
    "                 {'dataframe':df_microsoft, 'name': 'microsoft'},\n",
    "                 {'dataframe':df_nvidia, 'name': 'nvidia'},\n",
    "                 {'dataframe':df_sony, 'name': 'sony'},  \n",
    "                ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a890ab59-fa43-4a37-b316-70f405969695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in dict_companies['companies']:\n",
    "    company[\"dataframe\"] = company[\"dataframe\"].withColumn(\"company_name\", lit(company[\"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ec7e75-aa7d-4f14-9ab7-c6b057c92a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = dict_companies['companies'][0]['dataframe'].union(dict_companies['companies'][1]['dataframe']).union(dict_companies['companies'][2]['dataframe']).union(dict_companies['companies'][3]['dataframe']).union(dict_companies['companies'][4]['dataframe']).union(dict_companies['companies'][5]['dataframe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8391cab-b951-47fd-869a-ce59d1c8010e",
   "metadata": {},
   "source": [
    "## Filtro dos dados das varias empresas\n",
    "\n",
    "Filtragem de Dados: os dados foram filtrados com base no t√≠tulo do v√≠deo e no nome do canal em cada regi√£o, mantendo apenas aqueles que mencionam diretamente as empresas alvo. Esta etapa foi essencial para garantir que os dados refletiam a rela√ß√£o com as empresas analisadas.\n",
    "\n",
    "O filtro foi realizado nas colunas title e channelTitle, enquanto as demais colunas foram desconsideradas devido ao grande volume de ru√≠do. Um exemplo claro disso s√£o as colunas de tags e coment√°rios. O ru√≠do ocorre porque v√≠deos postados por pessoas que buscam alcan√ßar um p√∫blico mais amplo frequentemente incluem tags e informa√ß√µes com palavras-chave relacionadas a empresas ou √°reas com grande n√∫mero de interessados. Isso faz com que o algoritmo do YouTube mostre esses v√≠deos com mais frequ√™ncia para utilizadores que demonstram interesse nessas palavras-chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844d89c4-b292-4134-afd2-0b4339ab22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['nvidia', 'dell', 'ibm', 'intel', 'microsoft', 'sony']\n",
    "countries_df = [df_us, df_br, df_ca, df_fr, df_gb, df_in, df_kr, df_mx]\n",
    "countries = ['us', 'br', 'ca', 'fr', 'gb', 'in', 'kr', 'mx']\n",
    "\n",
    "yt = {company: {} for company in companies}\n",
    "\n",
    "def filter_df(df, company):\n",
    "    filtered_df = df.filter(\n",
    "        (col('title').contains(company.capitalize())) |\n",
    "        (col('title').contains(company.upper())) |\n",
    "        (col('channelTitle').contains(company.capitalize())) |\n",
    "        (col('channelTitle').contains(company.upper()))\n",
    "    )\n",
    "    return filtered_df.withColumn(\"company\", lit(company))\n",
    "\n",
    "for company in companies:\n",
    "    for country, country_df in zip(countries, countries_df):\n",
    "        filtered_data = filter_df(country_df, company)\n",
    "        yt[company].setdefault(country, []).append(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171c121-7412-4d2c-b269-46853043035e",
   "metadata": {},
   "source": [
    "## Uni√£o dos df de cada pais num s√≥\n",
    "Para facilmente ser analisado os dados de cada empresa, juntou se todos os dados num so dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4905d61-5998-4b6c-8487-eac04ead3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [\n",
    "    df \n",
    "    for company, country_data in yt.items() \n",
    "    for country, dfs in country_data.items() \n",
    "    for df in dfs\n",
    "]\n",
    "\n",
    "if all_dfs:\n",
    "    df_yt = reduce(lambda df1, df2: df1.union(df2), all_dfs)\n",
    "else:\n",
    "    df_yt = None  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dca3a9-7e86-4ff1-ad55-d99d234f228b",
   "metadata": {},
   "source": [
    "## Colunas existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba186382-89a3-4cab-a987-d4639ac8a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d0970c8-26e2-4cfc-8972-34927781c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_companies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3b68738-5875-4f75-b365-d3723547df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de8496c2-c7f9-47a5-b969-d6dbfc0db6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_companies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23a022-a979-476f-9198-07527684b2e3",
   "metadata": {},
   "source": [
    "## Uni√£o dos videos de cada empresa\n",
    "df_yt_companies - todos os videos das empresas a serem estudadas<br> \n",
    "df_all_companies - dados de todas as empreas a serem estudadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e4ec1-1c33-4e91-ab6f-eb803a40f014",
   "metadata": {},
   "source": [
    "## Estudo dos nulos e duplicados\n",
    "\n",
    "A existencia de nulos em analises de dados √© um problema que tem de ser sempre tratado. O mesmo em rela√ß√£o aos duplicados (um problema que tinhamos em grandes quantidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d84b29-bf06-4d1c-91b7-773dd9aa35e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "|_id|categoryId|channelId|channelTitle|comment_count|comments_disabled|description|dislikes|likes|publishedAt|ratings_disabled|tags|thumbnail_link|title|trending_date|video_id|view_count|company|\n",
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "|  0|         0|        0|           0|            0|                0|          0|       0|    0|          0|               0|   0|             0|    0|            0|       0|         0|      0|\n",
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if df_yt is not None:\n",
    "    df_yt.select([count(when(col(c).isNull(), c)).alias(c) for c in df_yt.columns]).show()\n",
    "else:\n",
    "    print(\"df_yt is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62851687-e1f8-4851-a551-13361055cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "|EVGA Terminates N...|   18|\n",
      "|I've never held s...|    9|\n",
      "|BREAKING NEWS! - ...|   15|\n",
      "|NVIDIA... You've ...|   18|\n",
      "|NVIDIA GeForce RT...|   15|\n",
      "|Nvidia was clearl...|   19|\n",
      "|ITS HERE - NVIDIA...|   16|\n",
      "|NVIDIA finally an...|    5|\n",
      "|NVIDIA REFUSED To...|   14|\n",
      "|NVIDIA GeForce RT...|   13|\n",
      "|NVIDIA just made ...|   22|\n",
      "|Nvidia tried to b...|    8|\n",
      "|NVIDIA 40 Series ...|    9|\n",
      "|Nvidia, you PROMI...|   14|\n",
      "|NVIDIA Never saw ...|   15|\n",
      "|NVIDIA expects to...|    4|\n",
      "|NVIDIA RTX 3090, ...|   13|\n",
      "|NVIDIA... why do ...|   18|\n",
      "|NVIDIA's RTX 4080...|   28|\n",
      "|Black Myth: Wukon...|   14|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_yt.groupBy(\"title\").count().filter(\"count > 1\")\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "134f10ab-aa45-40a1-9f98-c6fc41b088ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt = df_yt.dropDuplicates([\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21001632-c0c2-410e-aeef-1cba1284f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "|Adj Close|Close|Date|High|Low|Open|Volume|_id|company_name|\n",
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "|        0|    0|   0|   0|  0|   0|     0|  0|           0|\n",
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_companies.select([count(when(col(c).isNull(), c)).alias(c) for c in df_companies.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f57966e7-751a-4b97-8e68-4405f95b1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date|count|\n",
      "+----------+-----+\n",
      "|2016-08-17|    6|\n",
      "|2017-12-05|    6|\n",
      "|2019-08-08|    6|\n",
      "|2019-08-22|    6|\n",
      "|2019-08-23|    6|\n",
      "|2020-02-26|    6|\n",
      "|2020-04-13|    6|\n",
      "|2021-11-03|    6|\n",
      "|2022-10-05|    6|\n",
      "|2023-05-01|    6|\n",
      "|2023-05-18|    6|\n",
      "|2024-01-19|    6|\n",
      "|2024-08-20|    5|\n",
      "|2024-10-24|    5|\n",
      "|2017-02-24|    6|\n",
      "|2017-05-11|    6|\n",
      "|2017-10-20|    6|\n",
      "|2017-12-22|    6|\n",
      "|2018-12-31|    6|\n",
      "|2019-04-25|    6|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_companies.groupBy(\"Date\").count().filter(\"count > 1\")\n",
    "duplicates.show()\n",
    "\n",
    "df_cleaned = df_companies.dropDuplicates([\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b07b94-4bc3-4346-8ef6-40f14fe19fad",
   "metadata": {},
   "source": [
    "## Passar publishedAt e Date de string para data\n",
    "\n",
    "De forma a posteriormente ser utilizado nas visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71454d16-f22d-4645-8d24-b0ec5ca5f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt = df_yt.withColumn(\n",
    "    \"publishedAt\",\n",
    "    to_date(df_yt.publishedAt, \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0927a1e-6eac-4298-93bf-0c2beef0bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = df_companies.withColumn(\n",
    "    \"Date\",\n",
    "    to_date(df_companies.Date, \"yyyy-MM-dd\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fe892-ea1a-4103-9b4d-e52559f6de75",
   "metadata": {},
   "source": [
    "## Tags String to Array sem nulos\n",
    "\n",
    "para mais facilmente ser utilizado em termos de visualiza√ß√µes, transformamos a coluna das tags em um array de string. Posteriormente, se o array for nulo, a tag passa a ser o nome da companhia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43296acc-6752-4eff-b7eb-5e1e18e2272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_yt.withColumn(\"tags_arr\", split(col(\"tags\"), \"\\|\")).drop(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9670c266-4287-4a7f-8ab4-660932cb93d6",
   "metadata": {},
   "source": [
    "Como o c√≥digo estava antes, quer√≠amos que funcionasse, mas o PySpark entrou em breakdwn e arrebentou com o kernel. Isso ocorreu porque n√£o havia RAM suficiente (a RAM do Docker n√£o permite mais do que 7 GB alocados no nosso cont√™iner).\n",
    "\n",
    "Posteriormente, por n√£o conseguirmos encontrar solu√ß√µes na internet, decidimos deixar uma vers√£o mais simplificada.\n",
    "\n",
    "No c√≥digo de filtro dos dados, o mesmo aconteceu quando tentamos usar regex para retirar mais facilmnte o \n",
    "\n",
    "```python\n",
    "# no caso das tags\n",
    "df_transformed = df_yt.withColumn(\n",
    "    \"tags_arr\",\n",
    "    when(col(\"tags\").isNull() | (col(\"tags\") == \"\"), col(\"company_name\")) \n",
    "    .otherwise(split(col(\"tags\"), \"\\|\"))  \n",
    ").drop(\"tags\")) \n",
    "\n",
    "#no caso do regex\n",
    "\n",
    "pattern = r'\\b' + re.escape(company) + r'\\b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f171a17-df6d-44e6-9669-991e5ec879f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o1987.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_transformed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags_arr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o1987.showString"
     ]
    }
   ],
   "source": [
    "df_transformed.select(\"tags_arr\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54c81e-f2bd-4cde-8b77-9735f2a5f5c9",
   "metadata": {},
   "source": [
    "## Meter os dados filtrados na Database final do mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e2eaa-f66f-4074-bcf5-f72f09439cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt.write.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.youtube\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "df_companies.write.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.company\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Dados processados e salvos com sucesso.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
