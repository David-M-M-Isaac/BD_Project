{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb50b77f-ab6c-4a76-8970-087b006dae0b",
   "metadata": {},
   "source": [
    "# üìú An√°lise de dados entre videos do Youtube e os stocks de grandes empresas üìú "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6731474-e146-48b5-8d6a-b10fbe9b456e",
   "metadata": {},
   "source": [
    "Desde a estabiliza√ß√£o do com√©rcio internacional a n√≠vel mundial que as empresas t√™m tido um crescimento exponencial, impulsionado por diversos fatores, incluindo a inova√ß√£o tecnol√≥gica e a globaliza√ß√£o. Nos √∫ltimos anos, o crescimento de plataformas de divulga√ß√£o e compartilhamento de v√≠deos t√™m um papel significativo na promo√ß√£o de marcas, produtos e servi√ßos, influenciando a percep√ß√£o dos consumidores e, consequentemente, o desempenho financeiro das empresas. <br>\n",
    "\n",
    "Este projeto tem como objetivo analisar o impacto das visualiza√ß√µes de v√≠deos no YouTube sobre empresas espec√≠ficas, avaliando como a exposi√ß√£o digital pode influenciar o crescimento das organiza√ß√µes e o valor das suas a√ß√µes no mercado bolsista. Atrav√©s de uma abordagem que combina an√°lise de dados, economia e marketing digital, pretende-se compreender de que forma m√©tricas como visualiza√ß√µes, intera√ß√µes e popularidade de conte√∫do podem ser indicadores de tend√™ncias de investimento e valoriza√ß√£o empresarial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9976a-8981-47bc-aea4-45712010878f",
   "metadata": {},
   "source": [
    "## Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73834437-850c-4a9d-8213-5bb85526c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from matplotlib import cbook, cm\n",
    "from matplotlib.colors import LightSource\n",
    "#import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70724a25-31ce-49b2-9142-0688ffef9bd5",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do Spark para ser utilizado em PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c863b017-fa74-4c6e-ac94-0f5e8e2e60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_ = SparkSession.builder \\\n",
    "    .appName(\"company_database\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongodb:27017/Company_Database\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongodb:27017/Company_Database\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongodb:27017/Youtube_Database\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongodb:27017/Youtube_Database\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cf114-4c96-4d40-ac49-355fa38de3ff",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Para a realiza√ß√£o deste trabalho, foram utilizados 14 datasets que se dividem em dois grupos principais: os datasets de v√≠deos do YouTube e datasets de stocks de empresas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f8fc4-3a7f-481f-91fd-3e360a75f092",
   "metadata": {},
   "source": [
    "## Importan√ß√£o dos dados de cada pais\n",
    "Datasets de v√≠deos do youtube <br>\n",
    "Os dados destes datasets s√£o provenientes de oito diferentes pa√≠ses, dos quais: Brasil, Estados Unidos (US), Canad√°, Fran√ßa, Inglaterra, √çndia, Coreia do Sul e M√©xico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96c35168-23c6-417c-8eef-e79a4404dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_us\").load()\n",
    "df_br = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_br\").load()\n",
    "df_ca = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_ca\").load()\n",
    "df_fr = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_fr\").load()\n",
    "df_gb = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_gb\").load()\n",
    "df_in = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_in\").load()\n",
    "df_kr = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_kr\").load()\n",
    "df_mx = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Youtube_Database.youtube_data_mx\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c28df-34bf-4db7-9e96-c51ba55e3c2c",
   "metadata": {},
   "source": [
    "## Importan√ß√£o dos dados de empresa\n",
    "Datasets de stocks de empresas <br>\n",
    "Os datasets sobre os stocks de empresas fornecem dados de seis organiza√ß√µes distintas: Sony, Nvidia, Microsoft, Dell, IBM, Intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e930414f-e83c-41b7-bcf2-f9ebb14ae59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dell = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.dell_data\").load()\n",
    "df_ibm = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.ibm_data\").load()\n",
    "df_intel = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.intel_data\").load()\n",
    "df_microsoft = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.microsoft_data\").load()\n",
    "df_nvidia = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.nvidia_data\").load()\n",
    "df_sony = spark_.read.format(\"mongo\").option(\"uri\", \"mongodb://mongodb:27017/Company_Database.sony_data\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71688b-f487-49ec-9dc6-00aa0e1d20d7",
   "metadata": {},
   "source": [
    "## Dicionario das empresas e seus nomes para posteriormente fazer a uni√£o dos dfs com a coluna company_name\n",
    "A ideia √© juntar todos os dataframes num s√≥. Para isso, necessitamos de criar uma nova coluna que identifique a que empresa a linha do stock est√° ligada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa3911b-e194-4b90-a298-ee060f735779",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_companies = {'companies': [\n",
    "                 {'dataframe':df_dell, 'name': 'dell'},\n",
    "                 {'dataframe':df_ibm, 'name': 'ibm'},\n",
    "                 {'dataframe':df_intel, 'name': 'intel'},\n",
    "                 {'dataframe':df_microsoft, 'name': 'microsoft'},\n",
    "                 {'dataframe':df_nvidia, 'name': 'nvidia'},\n",
    "                 {'dataframe':df_sony, 'name': 'sony'},  \n",
    "                ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a890ab59-fa43-4a37-b316-70f405969695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in dict_companies['companies']:\n",
    "    company[\"dataframe\"] = company[\"dataframe\"].withColumn(\"company_name\", lit(company[\"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3ec7e75-aa7d-4f14-9ab7-c6b057c92a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = dict_companies['companies'][0]['dataframe'].union(dict_companies['companies'][1]['dataframe']).union(dict_companies['companies'][2]['dataframe']).union(dict_companies['companies'][3]['dataframe']).union(dict_companies['companies'][4]['dataframe']).union(dict_companies['companies'][5]['dataframe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "844d89c4-b292-4134-afd2-0b4339ab22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['nvidia', 'dell', 'ibm', 'intel', 'microsoft', 'sony']\n",
    "countries_df = [df_us, df_br, df_ca, df_fr, df_gb, df_in, df_kr, df_mx]\n",
    "countries = ['us', 'br', 'ca', 'fr', 'gb', 'in', 'kr', 'mx']\n",
    "\n",
    "yt = {company: {} for company in companies}\n",
    "\n",
    "def filter_df(df, company):\n",
    "    filtered_df = df.filter(\n",
    "        (col('title').contains(company.capitalize())) |\n",
    "        (col('title').contains(company.upper())) |\n",
    "        (col('channelTitle').contains(company.capitalize())) |\n",
    "        (col('channelTitle').contains(company.upper()))\n",
    "    )\n",
    "    return filtered_df.withColumn(\"company\", lit(company))\n",
    "\n",
    "for company in companies:\n",
    "    for country, country_df in zip(countries, countries_df):\n",
    "        filtered_data = filter_df(country_df, company)\n",
    "        yt[company].setdefault(country, []).append(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171c121-7412-4d2c-b269-46853043035e",
   "metadata": {},
   "source": [
    "## Uni√£o dos df de cada pais num s√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4905d61-5998-4b6c-8487-eac04ead3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [\n",
    "    df \n",
    "    for company, country_data in yt.items() \n",
    "    for country, dfs in country_data.items() \n",
    "    for df in dfs\n",
    "]\n",
    "\n",
    "if all_dfs:\n",
    "    df_yt = reduce(lambda df1, df2: df1.union(df2), all_dfs)\n",
    "else:\n",
    "    df_yt = None  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dca3a9-7e86-4ff1-ad55-d99d234f228b",
   "metadata": {},
   "source": [
    "## Colunas existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba186382-89a3-4cab-a987-d4639ac8a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d0970c8-26e2-4cfc-8972-34927781c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_companies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3b68738-5875-4f75-b365-d3723547df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de8496c2-c7f9-47a5-b969-d6dbfc0db6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_companies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23a022-a979-476f-9198-07527684b2e3",
   "metadata": {},
   "source": [
    "## Uni√£o dos videos de cada empresa\n",
    "df_yt_companies - todos os videos das empresas a serem estudadas<br> \n",
    "df_all_companies - dados de todas as empreas a serem estudadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e4ec1-1c33-4e91-ab6f-eb803a40f014",
   "metadata": {},
   "source": [
    "## Estudo dos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48faae3f-9433-4af6-87ac-b9606ffd78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "|_id|categoryId|channelId|channelTitle|comment_count|comments_disabled|description|dislikes|likes|publishedAt|ratings_disabled|tags|thumbnail_link|title|trending_date|video_id|view_count|company|\n",
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "|  0|         0|        0|           0|            0|                0|          0|       0|    0|          0|               0|   0|             0|    0|            0|       0|         0|      0|\n",
      "+---+----------+---------+------------+-------------+-----------------+-----------+--------+-----+-----------+----------------+----+--------------+-----+-------------+--------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YT\n",
    "df_yt.select([count(when(col(c).isNull(), c)).alias(c) for c in df_yt.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62851687-e1f8-4851-a551-13361055cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "|EVGA Terminates N...|   18|\n",
      "|I've never held s...|    9|\n",
      "|BREAKING NEWS! - ...|   15|\n",
      "|NVIDIA... You've ...|   18|\n",
      "|NVIDIA GeForce RT...|   15|\n",
      "|Nvidia was clearl...|   19|\n",
      "|ITS HERE - NVIDIA...|   16|\n",
      "|NVIDIA finally an...|    5|\n",
      "|NVIDIA REFUSED To...|   14|\n",
      "|NVIDIA GeForce RT...|   13|\n",
      "|NVIDIA just made ...|   22|\n",
      "|Nvidia tried to b...|    8|\n",
      "|NVIDIA 40 Series ...|    9|\n",
      "|Nvidia, you PROMI...|   14|\n",
      "|NVIDIA Never saw ...|   15|\n",
      "|NVIDIA expects to...|    4|\n",
      "|NVIDIA RTX 3090, ...|   13|\n",
      "|NVIDIA... why do ...|   18|\n",
      "|NVIDIA's RTX 4080...|   28|\n",
      "|Black Myth: Wukon...|   14|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_yt.groupBy(\"title\").count().filter(\"count > 1\")\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "134f10ab-aa45-40a1-9f98-c6fc41b088ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt = df_yt.dropDuplicates([\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21001632-c0c2-410e-aeef-1cba1284f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "|Adj Close|Close|Date|High|Low|Open|Volume|_id|company_name|\n",
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "|        0|    0|   0|   0|  0|   0|     0|  0|           0|\n",
      "+---------+-----+----+----+---+----+------+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_companies.select([count(when(col(c).isNull(), c)).alias(c) for c in df_companies.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57966e7-751a-4b97-8e68-4405f95b1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date|count|\n",
      "+----------+-----+\n",
      "|2016-08-17|    6|\n",
      "|2017-12-05|    6|\n",
      "|2019-08-08|    6|\n",
      "|2019-08-22|    6|\n",
      "|2019-08-23|    6|\n",
      "|2020-02-26|    6|\n",
      "|2020-04-13|    6|\n",
      "|2021-11-03|    6|\n",
      "|2022-10-05|    6|\n",
      "|2023-05-01|    6|\n",
      "|2023-05-18|    6|\n",
      "|2024-01-19|    6|\n",
      "|2024-08-20|    5|\n",
      "|2024-10-24|    5|\n",
      "|2017-02-24|    6|\n",
      "|2017-05-11|    6|\n",
      "|2017-10-20|    6|\n",
      "|2017-12-22|    6|\n",
      "|2018-12-31|    6|\n",
      "|2019-04-25|    6|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_companies.groupBy(\"Date\").count().filter(\"count > 1\")\n",
    "duplicates.show()\n",
    "\n",
    "df_cleaned = df_companies.dropDuplicates([\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b07b94-4bc3-4346-8ef6-40f14fe19fad",
   "metadata": {},
   "source": [
    "## Passar publishedAt e Date de string para data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71454d16-f22d-4645-8d24-b0ec5ca5f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt = df_yt.withColumn(\n",
    "    \"publishedAt\",\n",
    "    to_date(df_yt.publishedAt, \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0927a1e-6eac-4298-93bf-0c2beef0bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = df_companies.withColumn(\n",
    "    \"Date\",\n",
    "    to_date(df_companies.Date, \"yyyy-MM-dd\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fe892-ea1a-4103-9b4d-e52559f6de75",
   "metadata": {},
   "source": [
    "## Tags String to Array sem nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43296acc-6752-4eff-b7eb-5e1e18e2272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_yt.withColumn(\"tags_arr\", split(col(\"tags\"), \"\\|\")).drop(\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f171a17-df6d-44e6-9669-991e5ec879f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            tags_arr|\n",
      "+--------------------+\n",
      "|            [[None]]|\n",
      "|[Microsoft Surfac...|\n",
      "|[call of duty, co...|\n",
      "|[sony pal shows, ...|\n",
      "|[deepthi sunaina ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.select(\"tags_arr\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8e2eaa-f66f-4074-bcf5-f72f09439cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados processados e salvos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Salvar no MongoDB com modo append\n",
    "df_yt.write.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.Youtube\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "df_companies.write.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.Company\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Dados processados e salvos com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb79b81-d786-48f6-920a-c4521df9c82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
