{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41007742-163c-4f7c-b7d3-33b0dbba4b51",
   "metadata": {},
   "source": [
    "# Carregamento dos Relatórios do MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87632a-8fa0-4f0f-9caf-9c40b2996e1a",
   "metadata": {},
   "source": [
    "## Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bdf2185-4440-471a-85b3-48700cd2e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import sum\n",
    "from matplotlib import cbook, cm\n",
    "from matplotlib.colors import LightSource \n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd070c0-94fb-4fa3-956a-8aa9ee59ea76",
   "metadata": {},
   "source": [
    "## Carregamento das Análises Feitas com os Dados na Base de Dados para os Relatórios de Cada Empresa\n",
    "\n",
    "As análises combinaram dados do YouTube e do mercado de ações para gerar relatórios detalhados por empresa.\n",
    "\n",
    "### Etapas do Processo\n",
    "\n",
    "#### Processamento do YouTube:\n",
    "- Consolidamos métricas diárias (*visualizações*, *curtidas*, *comentários*).  \n",
    "- Identificamos o vídeo mais relevante por empresa e por dia.\n",
    "\n",
    "#### Processamento dos Dados de Mercado:\n",
    "- Agregamos métricas diárias (*peak maximo*, *peak minimo*, *volume* e *stock final*).\n",
    "- Calculamos médias gerais de *stocks* para cada empresa.\n",
    "\n",
    "#### Integração e Análise:\n",
    "- Combinamos dados por empresa e data.  \n",
    "- Calculamos movimentações diárias de *stocks* e estruturamos os relatórios com métricas agregadas.\n",
    "\n",
    "#### Armazenamento:\n",
    "- Criamos *DataFrames* individuais para cada empresa.  \n",
    "- Salvamos os relatórios no MongoDB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65807e91-3c6a-4454-adae-e26e5a6fa642",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_ = SparkSession.builder \\\n",
    "    .appName(\"Data Integration\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_youtube = spark_.read.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.youtube\").load()\n",
    "\n",
    "df_company = spark_.read.format(\"mongo\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/Final_Database.company\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "708e33be-3169-4aad-9207-e6fe427286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['nvidia', 'dell', 'ibm', 'intel', 'microsoft', 'sony']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0729b4e-9792-4c0b-a9d8-fd08d6fed04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados processados e salvos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "df_youtube = df_youtube.withColumn(\"day\", F.to_date(df_youtube[\"publishedAt\"]))\n",
    "\n",
    "window_spec = Window.partitionBy(\"company\", \"day\").orderBy(F.desc(\"view_count\"))\n",
    "\n",
    "df_youtube_with_rank = df_youtube.withColumn(\n",
    "    \"rank\", F.row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "df_youtube_top_video = df_youtube_with_rank.filter(F.col(\"rank\") == 1)\n",
    "\n",
    "df_youtube_daily = df_youtube_top_video.groupBy(\"company\", \"day\").agg(\n",
    "    F.sum(\"view_count\").alias(\"total_views\"),\n",
    "    F.sum(\"likes\").alias(\"total_likes\"),\n",
    "    F.sum(\"dislikes\").alias(\"total_dislikes\"),\n",
    "    F.sum(\"comment_count\").alias(\"total_coments\"),\n",
    "    F.first(\"title\").alias(\"top_video\")  \n",
    ")\n",
    "df_company = df_company.withColumn(\"day\", F.to_date(df_company[\"Date\"])) \n",
    "df_company_daily = df_company.groupBy(\"company_name\", \"day\").agg(\n",
    "    F.max(\"High\").alias(\"stock_high\"),\n",
    "    F.min(\"Low\").alias(\"stock_low\"),\n",
    "    F.avg(\"Volume\").alias(\"Volume\"),\n",
    "    F.avg(\"Close\").alias(\"final_stocks\")  \n",
    ")\n",
    "df_report = df_youtube_daily.alias(\"youtube\").join(\n",
    "    df_company_daily.alias(\"company\"),\n",
    "    (F.col(\"youtube.company\") == F.col(\"company.company_name\")) & (F.col(\"youtube.day\") == F.col(\"company.day\")),\n",
    "    \"left\"\n",
    ").join(\n",
    "    df_company_avg_stocks.alias(\"avg_stocks\"),\n",
    "    F.col(\"youtube.company\") == F.col(\"avg_stocks.company_name\"),\n",
    "    \"left\"\n",
    ")\n",
    "df_report = df_report.withColumn(\n",
    "    \"final_stocks\",\n",
    "    F.coalesce(F.col(\"final_stocks\"), F.lit(0))  \n",
    ")\n",
    "window_spec = Window.partitionBy(\"youtube.company\").orderBy(\"youtube.day\")\n",
    "\n",
    "df_report = df_report.withColumn(\n",
    "    \"previous_final_stocks\",\n",
    "    F.coalesce(F.lag(\"final_stocks\").over(window_spec), F.lit(0))  \n",
    ")\n",
    "df_report = df_report.withColumn(\n",
    "    \"stocks_movement\",\n",
    "    (F.col(\"final_stocks\") - F.col(\"previous_final_stocks\")).cast(\"float\")\n",
    ")\n",
    "df_report = df_report.withColumn(\n",
    "    \"top_video\",\n",
    "    F.concat_ws(\",\", F.col(\"top_video\"))\n",
    ")\n",
    "df_report = df_report.drop(\"company_name\")  \n",
    "\n",
    "company_dfs = {}\n",
    "\n",
    "for company_name in companies:\n",
    "    company_report = df_report.filter(F.col(\"youtube.company\") == company_name)\n",
    "    company_dfs[company_name] = company_report\n",
    "\n",
    "for company_name, company_df in company_dfs.items():\n",
    "    company_df.write.format(\"mongo\") \\\n",
    "        .option(\"uri\", f\"mongodb://mongodb:27017/Relatorio.{company_name.lower()}\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "print(\"Dados processados e salvos com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
